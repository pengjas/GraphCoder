{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiyao_yang/anaconda3/envs/graphgpt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, AutoModelForCausalLM, AutoTokenizer\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "llama_path = '/data/LPJ/Llama-2-7b-chat-hf'\n",
    "# llama_path = '/data/LPJ/Llama-2-7b-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(llama_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(llama_path, torch_dtype=torch.bfloat16, device_map=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '''Given a submodules interconnection graph: \\n<graph>\\n, \\nnodes: [{'id': 0, 'content': 'data_a'}, {'id': 1, 'content': 'iSAOUT'}, {'id': 2, 'content': 'out8'}, {'id': 3, 'content': 'led_0'}, {'id': 4, 'content': 'op1'}, {'id': 5, 'content': 'ripple_adder_32'}], \\nedge_attrs: [], \\nconnectivity: [[1, 4], [5, 4]]\\n, please find which nodes point to ripple_adder_32 node, and ripple_adder_32 node points to which nodes, \n",
    "you should use a template like below and just output content in this template, don't output anything else, like Explanation:\n",
    "{which nodes} points to {above node}, {above node} points to {which nodes}\n",
    "'''\n",
    "test = '''Given a submodules interconnection graph: \\n<graph>\\n, \\nnodes: [{'id': 0, 'content': 'data_a'}, {'id': 1, 'content': 'iSAOUT'}, {'id': 2, 'content': 'out8'}, {'id': 3, 'content': 'led_0'}, {'id': 4, 'content': 'op1'}, {'id': 5, 'content': 'ripple_adder_32'}], \\nedge_attrs: [], \\nconnectivity: [[1, 4], [5, 4]]\\n, please find which nodes point to ripple_adder_32 node, and ripple_adder_32 node points to which nodes, \n",
    "you should just output content in this template, don't output anything else, like Explanation:\n",
    "{which nodes} points to {above node}, {above node} points to {which nodes}\n",
    "'''\n",
    "inputs = tokenizer(test, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in inputs.items():\n",
    "    inputs[key] = value.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a submodules interconnection graph: \n",
      "<graph>\n",
      ", \n",
      "nodes: [{'id': 0, 'content': 'data_a'}, {'id': 1, 'content': 'iSAOUT'}, {'id': 2, 'content': 'out8'}, {'id': 3, 'content': 'led_0'}, {'id': 4, 'content': 'op1'}, {'id': 5, 'content': 'ripple_adder_32'}], \n",
      "edge_attrs: [], \n",
      "connectivity: [[1, 4], [5, 4]]\n",
      ", please find which nodes point to ripple_adder_32 node, and ripple_adder_32 node points to which nodes, \n",
      "you should just output content in this template, don't output anything else, like Explanation:\n",
      "{which nodes} points to {above node}, {above node} points to {which nodes}\n",
      "\n",
      "For example, if the answer is:\n",
      "{0, 1, 2} points to {ripple_adder_32}, ripple_adder_32 points to {0, 1, 2}\n",
      "\n",
      "Then, the output should be:\n",
      "{0, 1, 2} points to {ripple_adder_32}, ripple_adder_32 points to {0, 1, 2}\n",
      "\n",
      "Please let me know if you have any questions or need further clarification.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "outputs = model.generate(**inputs)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def seed_torch(seed=1029):\n",
    "\trandom.seed(seed)\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "\tnp.random.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch()\n",
    "\n",
    "# 定义一个网络\n",
    "class net(nn.Module):\n",
    "    def __init__(self, num_class=10):\n",
    "        super(net, self).__init__()\n",
    "        self.pool1 = nn.AvgPool1d(2)\n",
    "        self.bn1 = nn.BatchNorm1d(3)\n",
    "        self.fc1 = nn.Linear(12, 4)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        x = x.detach()  # 将非叶子节点剥离成叶子节点 x.requires_grad = False x.grad_fn=None\n",
    "\n",
    "        y = self.fc1(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "# 定义网络\n",
    "model = net()\n",
    "\n",
    "# 定义loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "# 定义训练数据\n",
    "x = torch.randn((3, 3, 8))\n",
    "\n",
    "# 训练前叶子结点 bn1.weight 的参数情况\n",
    "print(model.bn1.weight.requires_grad)\n",
    "print(model.bn1.weight.grad)\n",
    "\n",
    "# 训练前叶子结点 fc1.weight 的参数情况\n",
    "print(model.fc1.weight.requires_grad)\n",
    "print(model.fc1.weight.grad)\n",
    "\n",
    "output = model(x)\n",
    "target = torch.tensor([1, 1, 1])\n",
    "loss = loss_fn(output, target)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# 训练后叶子结点 bn1.weight 的参数情况\n",
    "print(model.bn1.weight.requires_grad)\n",
    "print(model.bn1.weight.grad)\n",
    "\n",
    "# 训练后叶子结点 fc1.weight 的参数情况\n",
    "print(model.fc1.weight.requires_grad)\n",
    "print(model.fc1.weight.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已创建文件夹及其子文件夹：/data/LPJ/ICML25/GraphCoder/test_mkdir/son_dir\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/data/LPJ/ICML25/GraphCoder/test_mkdir/son_dir'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "print(f\"已创建文件夹及其子文件夹：{folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(\n",
    "        '/data/LPJ/bert/bert-L12-H128-uncased',\n",
    "        model_max_length=25,\n",
    "        padding_side=\"right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_node_attri = ['aaaaaa', 'i am your father and you are my son']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = bert_tokenizer(\n",
    "            raw_node_attri,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",\n",
    "            max_length=bert_tokenizer.model_max_length,\n",
    "            truncation=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 13360, 11057,  2050,   102,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [  101,  1045,  2572,  2115,  2269,  1998,  2017,  2024,  2026,  2365,\n",
       "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1093260329.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    **rslt\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "**rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.pad_token\n",
    "bert_tokenizer.pad_token_id\n",
    "bert_tokenizer.eos_token\n",
    "bert_tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiyao_yang/anaconda3/envs/graphgpt/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('/data/LPJ/bert/bert-L12-H128-uncased', torch_dtype=torch.bfloat16, device_map='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-1.0312,  0.3008, -0.7188,  ...,  0.0064, -0.4648, -0.2490],\n",
       "         [ 0.9688,  0.0889, -1.5938,  ..., -1.3750, -1.2656,  0.4629],\n",
       "         [ 1.0312, -0.9570, -1.5781,  ..., -1.0781, -1.2734, -0.1660],\n",
       "         ...,\n",
       "         [-0.3438,  0.1875, -0.5508,  ...,  0.0659, -0.0747,  0.2158],\n",
       "         [-0.1426,  0.1514, -0.8008,  ...,  0.0449, -0.1279,  0.2773],\n",
       "         [ 0.6211,  0.3379, -1.4375,  ..., -1.1484, -1.0625,  0.2852]],\n",
       "\n",
       "        [[-0.9727,  0.1641,  1.3516,  ..., -0.9727, -0.2363, -0.7422],\n",
       "         [ 0.7383, -0.8555,  0.1631,  ..., -1.5000,  1.0312,  0.2041],\n",
       "         [ 0.5195, -0.2754, -0.3008,  ..., -0.8789,  1.4922, -0.9648],\n",
       "         ...,\n",
       "         [ 0.5273, -1.1719,  0.5039,  ..., -0.2432,  0.2021, -0.3262],\n",
       "         [-0.0352,  0.0500,  1.1016,  ..., -1.3906, -0.7852,  0.7070],\n",
       "         [-1.1328, -0.5664,  0.3320,  ..., -0.3438, -0.3457, -0.6289]]],\n",
       "       dtype=torch.bfloat16, grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 9.9609e-01,  6.4844e-01, -8.8281e-01,  7.8516e-01, -9.6094e-01,\n",
       "         -8.9062e-01,  8.6426e-02,  3.8574e-02, -1.7188e-01,  9.5703e-01,\n",
       "          9.9609e-01, -9.8047e-01,  6.7383e-02,  7.0312e-01, -9.1016e-01,\n",
       "         -4.4727e-01,  2.7344e-02, -3.2031e-01, -8.3594e-01,  7.2656e-01,\n",
       "         -9.4141e-01,  1.0000e+00,  8.8672e-01,  1.0000e+00, -9.0625e-01,\n",
       "          3.4180e-02,  4.0039e-02, -9.5703e-01,  7.3828e-01,  8.9062e-01,\n",
       "          8.3594e-01,  9.6875e-01,  1.6406e-01,  3.7109e-02,  5.7678e-03,\n",
       "          2.9688e-01, -9.1016e-01, -9.9609e-01, -2.3535e-01, -9.8047e-01,\n",
       "          9.5312e-01, -7.8516e-01,  9.8047e-01,  1.9336e-01,  6.7188e-01,\n",
       "          7.8516e-01, -6.9531e-01, -6.5625e-01, -7.8906e-01,  8.4375e-01,\n",
       "          8.1250e-01,  3.6133e-01,  9.8047e-01, -9.6875e-01,  1.6724e-02,\n",
       "         -8.9844e-01,  5.9375e-01, -9.4141e-01,  3.1982e-02,  9.8438e-01,\n",
       "          9.8828e-01,  9.9219e-01,  7.3438e-01, -4.1748e-02, -3.9307e-02,\n",
       "         -9.1016e-01,  1.8457e-01,  4.0039e-01, -1.0000e+00, -4.4141e-01,\n",
       "          9.9609e-01,  1.0742e-01, -6.9922e-01, -8.1641e-01,  8.9453e-01,\n",
       "          9.8438e-01,  7.1484e-01,  9.8828e-01,  5.9082e-02,  8.5156e-01,\n",
       "          9.5312e-01, -9.2188e-01, -8.8281e-01, -9.0234e-01,  1.0010e-01,\n",
       "          9.4922e-01,  8.9844e-01,  4.4141e-01,  9.8438e-01,  8.1641e-01,\n",
       "         -5.8984e-01,  5.8984e-01, -1.0000e+00,  9.2188e-01, -6.7871e-02,\n",
       "         -1.3281e-01,  7.8516e-01,  1.9226e-03, -9.2969e-01, -8.1641e-01,\n",
       "         -4.9072e-02, -8.5938e-01, -9.3750e-01, -1.0000e+00,  5.3223e-02,\n",
       "          7.1094e-01,  9.6484e-01,  1.0000e+00,  4.0625e-01, -9.9609e-01,\n",
       "          8.7891e-01, -9.8828e-01,  5.1025e-02, -1.7773e-01, -7.2656e-01,\n",
       "         -4.9219e-01,  9.9219e-01, -9.7266e-01,  9.1797e-02, -8.8672e-01,\n",
       "         -2.5000e-01,  5.3516e-01, -9.8438e-01, -2.0605e-01, -8.6719e-01,\n",
       "         -9.9219e-01, -4.6875e-01, -9.4141e-01],\n",
       "        [ 1.0000e+00,  9.2578e-01, -3.6328e-01,  3.7891e-01, -9.7266e-01,\n",
       "         -5.6250e-01,  2.2754e-01, -6.9336e-02, -6.4453e-01,  9.4531e-01,\n",
       "          9.7266e-01, -2.3340e-01,  1.4551e-01,  6.8359e-01, -9.4141e-01,\n",
       "         -7.3047e-01, -2.6953e-01,  2.3242e-01, -2.3438e-01,  9.3750e-01,\n",
       "         -9.5703e-01,  1.0000e+00,  9.1016e-01,  1.0000e+00, -1.8359e-01,\n",
       "          9.7266e-01,  4.0283e-02, -9.8438e-01,  9.6484e-01,  7.1094e-01,\n",
       "          7.9688e-01,  1.0000e+00,  1.2402e-01,  5.0354e-04,  5.0049e-02,\n",
       "          6.2500e-01, -9.1797e-01, -1.0000e+00, -9.6094e-01, -7.8125e-01,\n",
       "          9.1406e-01, -6.6406e-01,  7.7344e-01,  6.4941e-02, -4.6094e-01,\n",
       "          9.5312e-01, -9.8047e-01, -9.6875e-01, -8.9844e-01,  9.5703e-01,\n",
       "          5.2734e-01,  8.6328e-01,  9.6094e-01, -5.7422e-01, -1.0010e-02,\n",
       "         -8.9453e-01,  8.0469e-01,  4.6387e-02, -1.0791e-01,  9.9219e-01,\n",
       "          8.2031e-01,  9.9219e-01,  3.8281e-01, -5.0781e-02, -5.1758e-02,\n",
       "         -6.2891e-01,  2.1680e-01, -7.7734e-01, -1.0000e+00,  5.4297e-01,\n",
       "          9.9609e-01, -2.8125e-01, -6.3281e-01, -9.8828e-01,  9.8438e-01,\n",
       "          6.1719e-01,  5.4688e-02,  9.8438e-01, -1.0938e-01,  9.1797e-01,\n",
       "          9.7266e-01, -9.5312e-01, -9.6875e-01, -9.4141e-01,  2.4902e-01,\n",
       "          7.2656e-01,  8.1641e-01,  8.3984e-01,  9.6875e-01,  9.6875e-01,\n",
       "         -6.7969e-01,  7.3828e-01, -1.0000e+00,  8.5938e-01, -1.8848e-01,\n",
       "          7.7734e-01, -8.5449e-02, -9.3262e-02, -3.3691e-02, -7.0312e-02,\n",
       "         -2.4707e-01, -7.2656e-01, -9.8438e-01, -1.0000e+00,  2.5391e-02,\n",
       "          5.3125e-01,  7.2266e-01,  1.0000e+00, -3.6377e-02, -1.0000e+00,\n",
       "          9.6875e-01, -1.0000e+00, -8.7891e-02, -1.9043e-01, -8.3594e-01,\n",
       "          1.9043e-01,  9.8828e-01, -9.8438e-01,  7.8613e-02, -9.4531e-01,\n",
       "          3.0078e-01,  7.2656e-01, -8.0078e-01, -1.4453e-01,  1.2793e-01,\n",
       "         -9.9609e-01, -7.8516e-01, -9.9219e-01]], dtype=torch.bfloat16,\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep = bert_model(**rslt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep.pooler_output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
