{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal"
        },
        {
            "name": "eval_db",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--tokenizer_path", "/data/LPJ/new_CodeLlama-7b-Instruct-hf",
                "--conv_mode", "graphchat_v1",
                "--bert_tokenizer_max_length", "25",
                "--bert_path", "/data/LPJ/bert/bert-L12-H128-uncased",
                "--model_name", "/data/LPJ/ICML25/all_checkpoints/debug_unfreeze_gnn/train_unfreeze_gnn_with_eval_dataset/with_module_head/v0_lr3e4_5epoch_batch2/last.ckpt",
                "--prompting_file", "/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/HiVerilog_Eval/graph_as_prefix/with_module_head/availiable_for_graphcoder/conversations.json",
                "--graph_data_path", "/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/HiVerilog_Eval/graph_as_prefix/with_module_head/availiable_for_graphcoder/graph.jsonl",
                "--output_res_path", "/data/LPJ/ICML25/GraphCoder/HiVerilog_eval_result/without_module_head/v2",
                "--num_gpus", "1",
                "--output_file_name", "eval_res",
                "--bf16", "True",
                "--f16", "False", 
                "--n_pass_k", "1",
                "--model_max_length", "3072",
                "--use_trained_gnn", "True",
            ]
        },
        {
            "name": "icml_db",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--model_name_or_path", "/data/LPJ/new_CodeLlama-7b-Instruct-hf",
                "--version", "v1",
                "--data_path", "/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/train_with_eval_dataset/with_module_head/graph_as_prefix/availiable_for_graphcoder/conversations.json",
                "--graph_content", "./arxiv_ti_ab.json",
                "--graph_data_path", "/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/train_with_eval_dataset/with_module_head/graph_as_prefix/availiable_for_graphcoder/graph_output.jsonl",
                "--graph_tower", "clip_gt_arxiv",
                "--tune_graph_mlp_adapter", "True",
                "--graph_select_layer", "-2",
                "--use_graph_start_end", "True",
                "--bf16", "True",
                "--output_dir", "/data/LPJ/ICML25/all_checkpoints/debug_unfreeze_gnn/train_unfreeze_gnn_with_eval_dataset/with_module_head/v2_lr1_1epoch_batch2_debug",
                "--num_train_epochs", "1",
                "--per_device_train_batch_size", "1",
                "--per_device_eval_batch_size", "1",
                "--real_batch_size", "2",
                "--gradient_accumulation_steps", "1",
                "--evaluation_strategy", "no",
                "--save_strategy", "steps",
                "--save_steps", "2400",
                "--save_total_limit", "1",
                "--learning_rate", "1",
                "--weight_decay", "0.",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "1",
                "--tf32", "True",
                "--model_max_length", "3072",
                "--gradient_checkpointing", "True",
                "--lazy_preprocess", "True",
                "--report_to", "wandb",
                "--fp16", "False",
                "--bert_path", "/data/LPJ/bert/bert-L12-H128-uncased",
                "--bert_gpu", "3",
                "--bert_tokenizer_max_length", "15",
                "--gpus", "0,1,2",
                "--freeze_backbone", "True",
                "--lora_enable", "True", 
                "--freeze_gnn", "False",
                "--model_save_name", "lr1_1epoch_batch2_debug"
            ]
        }
    ]
}