{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal"
        },
        {
            "name": "eval_db",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--tokenizer_path", "/data/LPJ/codev_codellama",
                "--conv_mode", "graphchat_v1",
                "--bert_tokenizer_max_length", "25",
                "--bert_path", "/data/LPJ/bert/bert-L12-H128-uncased",
                "--model_name", "/data/LPJ/ICML25/all_checkpoints/pretrain_qformer_havendeepseek_using_1989_57_without_lora/v1_cleaned_graph_20epoch_separate_lr_gnn2e3_qformer5e4/pretrain_qformer_havendeepseek_using_1989_57_without_lora_v1_cleaned_graph_20epoch_separate_lr_gnn2e3_qformer5e4.ckpt",
                "--prompting_file", "/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/HiVerilog_expansion_eval/with_head/clean_graph/conversations.json",
                "--graph_data_path", "/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/HiVerilog_expansion_eval/with_head/clean_graph/graph.jsonl",
                "--output_res_path", "/data/LPJ/ICML25/GraphCoder/pretraining_eval_result/train_unfreeze_gnn_with_tune_projector_without_lora_unified_lr_5k/v0_balanced_lr_8e3_2epoch_2batch",
                "--num_gpus", "1",
                "--output_file_name", "eval_res",
                "--bf16", "True",
                "--f16", "False", 
                "--n_pass_k", "1",
                "--model_max_length", "6912",
                "--use_trained_gnn", "True",
                "--lora_enable", "False",
                "--temperature", "0.1",
                "--num_query_tokens", "24",
                "--load_from_ckpt", "False",
                "--pretrain_input_embedding_path", "/data/LPJ/ICML25/all_checkpoints/pretrain_qformer_havenllama_using_1989_57_without_lora/v1_cleaned_graph_20epoch_separate_lr_gnn2e3_qformer5e4/pretrain_qformer_havenllama_using_1989_57_without_lora_v1_cleaned_graph_20epoch_separate_lr_gnn2e3_qformer5e4.ckpt",
                "--pretrain_graph_mlp_adapter", "/data/LPJ/ICML25/all_checkpoints/projector/pretrain_gnn_qformer_havenllama_using_1989_57_without_lora/v1_clean_graph_20epoch_separate_lr_gnn2e3_qformer5e4/projector.bin",
            ]
        },
        {
            "name": "icml_db",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--model_name_or_path", "/data/LPJ/CodeLlama-7b-Instruct-hf",
                "--version", "qwen",
                "--data_path", "/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/gpt_dataset_construction/stage2_1989_57/with_head/cleaned_graph/conversations.json",
                "--val_data_path", "/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/train_with_eval_dataset/with_module_head/graph_as_prefix/availiable_for_graphcoder/conversations.json",
                "--graph_content", "./arxiv_ti_ab.json",
                "--graph_data_path", "/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/gpt_dataset_construction/stage2_1989_57/with_head/cleaned_graph/graph.jsonl",
                "--val_graph_data_path", "/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/train_with_eval_dataset/with_module_head/graph_as_prefix/availiable_for_graphcoder/graph_output.jsonl",
                "--graph_tower", "clip_gcn_arxiv",
                "--tune_graph_mlp_adapter", "True",
                "--graph_select_layer", "-2",
                "--use_graph_start_end", "True",
                "--bf16", "True",
                "--output_dir", "/data/LPJ/ICML25/all_checkpoints/debug_unfreeze_gnn/train_unfreeze_gnn_with_eval_dataset/with_module_head/v2_lr1_1epoch_batch2_debug",
                "--num_train_epochs", "100",
                "--per_device_train_batch_size", "1",
                "--per_device_eval_batch_size", "1",
                "--real_batch_size", "2",
                "--gradient_accumulation_steps", "1",
                "--evaluation_strategy", "no",
                "--save_strategy", "steps",
                "--save_steps", "2400",
                "--save_total_limit", "1",
                "--learning_rate", "10",
                "--weight_decay", "0.",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "1",
                "--tf32", "True",
                "--model_max_length", "9216",
                "--gradient_checkpointing", "True",
                "--lazy_preprocess", "True",
                "--report_to", "wandb",
                "--fp16", "False",
                "--bert_path", "/data/LPJ/bert/bert-L12-H128-uncased",
                "--bert_gpu", "3",
                "--bert_tokenizer_max_length", "25",
                "--gpus", "1,2,3",
                "--freeze_backbone", "True",
                "--lora_enable", "False", 
                "--freeze_gnn", "False",
                "--model_save_name", "lr1_1epoch_batch2_debug",
                "--use_seperate_lr", "True",
                "--gnn_lr",  "8e-3",
                "--projector_lr", "3e-4" ,
                "--llm_lr", "3e-5",
                "--freeze_graph_mlp_adapter", "False",
                "--lora_r", "64",
                "--if_resume", "False",
                "--resume", "/data/LPJ/ICML25/all_checkpoints/pretrain_gnn_qformer_havenllama_using_1989_57_without_lora/v0_50epoch_separate_lr_gnn1e3_qformer_5e4/debug_checkpoint.ckpt",
                "--val_early_stop_threshold", "0.5",
                "--if_val", "False",
                "--num_query_token", "24",
                // "--pretrain_graph_mlp_adapter", "/data/LPJ/ICML25/all_checkpoints/projector/pretrain_gnn_qformer_havenllama_using_1989_57_without_lora/v0_50epoch_separate_lr_gnn1e3_qformer_5e4/projector.bin",
                // "--pretrain_input_embedding_path", "/data/LPJ/ICML25/all_checkpoints/pretrain_gnn_qformer_havenllama_using_1989_57_without_lora/v0_50epoch_separate_lr_gnn1e3_qformer_5e4/haven_llama_qformer_1989_57_pretrain_without_lora_50epoch_separate_lr_gnn1e3_qformer_5e4.ckpt"
            ]
        }
    ]
}