{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd12306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiyao_yang/anaconda3/envs/graphgpt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385131e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/data/LPJ/haven_codellama\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_path,\n",
    "            model_max_length=9216,\n",
    "            padding_side=\"right\",\n",
    "            use_fast=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca13eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 26163, 2571, 273, 562, 279], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "x = \"applebananacar\"\n",
    "print(tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9371ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = \"/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/gpt_dataset_construction/stage2_1989_57/conversations.jsonl\"\n",
    "text = pd.read_json(text_path, lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b04958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279.54037267080747\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(len(text)):\n",
    "    sum += len(tokenizer(text.iloc[i]['Instruction'])['input_ids'])\n",
    "print(sum/len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f51436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_graph_path = \"/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/gpt_dataset_construction/stage2_1989_57/with_head/cleaned_graph/conversations.json\"\n",
    "with open(text_graph_path, 'r') as f:\n",
    "    text_graph = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47baa142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Given a submodules interconnection graph: \\n<graph>\\n, \\nnodes: ['clk input', 'rst input', 'a input', 'b input', 'opcode input', 'result output', 'error output', 'u_adder submodule', 'u_subtractor submodule', 'u_and submodule', 'u_or submodule'], \\nconnectivity: [[2, 3, 2, 3, 2, 3, 2, 3, 7, 9, 8, 10], [7, 7, 8, 8, 9, 9, 10, 10, 5, 5, 5, 5]]\\n, Implement a modular Arithmetic Logic Unit (ALU) for 32-bit integers in Verilog. The top-level alu module should instantiate submodules for addition, subtraction, bitwise AND, and bitwise OR operations. The alu module uses these submodules to compute results based on an opcode.\\n\\nModule name:\\n    alu\\n\\nInput ports:\\n    clk: Clock signal for synchronous operations.\\n    rst: Reset signal, active high.\\n    a: 32-bit input operand A.\\n    b: 32-bit input operand B.\\n    opcode: 4-bit operation code (00 for ADD, 01 for SUB, 10 for AND, 11 for OR).\\n\\nOutput ports:\\n    result: 32-bit output resulting from the specified operation.\\n    error: Error flag, high if an undefined opcode is provided.\\n\\nImplementation:\\nThe module includes:\\nAdder Submodule:\\nThis submodule adds two 32-bit inputs.\\nSubtractor Submodule:\\nThis submodule subtracts the second 32-bit input from the first.\\nAND Submodule:\\nThis submodule performs a bitwise AND operation on two 32-bit inputs.\\nOR Submodule:\\nThis submodule performs a bitwise OR operation on two 32-bit inputs.\\nThe main alu module uses the opcode to select the appropriate operation and set the outputs accordingly.\\nGive me the complete code.\\nmodule alu(\\n    input clk,\\n    input rst,\\n    input [31:0] a,\\n    input [31:0] b,\\n    input [3:0] opcode,\\n    output reg [31:0] result,\\n    output reg error\\n);\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_graph[0]['conversations'][0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d405a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490.51293995859214\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(len(text_graph)):\n",
    "    sum += len(tokenizer(text_graph[i]['conversations'][0]['value'])['input_ids'])\n",
    "\n",
    "print(sum/len(text_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eca74d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356.9120879120879\n"
     ]
    }
   ],
   "source": [
    "inference_text_path = \"/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/HiVerilog_expansion_eval/for_text_llm/without_graph/conversations.jsonl\"\n",
    "inference_text = pd.read_json(inference_text_path, lines=True)\n",
    "sum = 0\n",
    "for i in range(len(inference_text)):\n",
    "    sum += len(tokenizer(inference_text.iloc[i]['Instruction'])['input_ids'])\n",
    "print(sum/len(inference_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d4ed73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.2307692307692\n"
     ]
    }
   ],
   "source": [
    "inference_text_graph_path = \"/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/HiVerilog_expansion_eval/for_text_llm/clean_graph/conversations.jsonl\"\n",
    "inference_text_graph = pd.read_json(inference_text_graph_path, lines=True)\n",
    "sum = 0\n",
    "for i in range(len(inference_text_graph)):\n",
    "    sum += len(tokenizer(inference_text_graph.iloc[i]['Instruction'])['input_ids'])\n",
    "print(sum/len(inference_text_graph))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
