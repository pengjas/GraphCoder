{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 读取 JSONL 文件\n",
    "df_text = pd.read_json('/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/train_with_eval_dataset/with_module_head/graph_as_prefix/conversations.jsonl', lines=True)\n",
    "df_mm = pd.read_json('/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/train_with_eval_dataset/with_module_head/graph_as_prefix/availiable_for_graphcoder/graph_output.jsonl', lines=True)\n",
    "\n",
    "# # 显示 DataFrame\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_lines = len(df_text)\n",
    "num_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Given a submodules interconnection graph: \\n<graph>\\n, \"\n",
    "# text_graph = '\\n{}\\n,'.format(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = []\n",
    "for i in range(num_lines):\n",
    "# for i in range(3):\n",
    "    new_line = []\n",
    "    graph = \"nodes: {}, \\nedge_attrs: {}, \\nconnectivity: {}\".format(df_mm['nodes'][i], df_mm['edge_attrs'][i], df_mm['connectivity'][i])\n",
    "    text_graph = \"\\n{}\\n, \".format(graph)\n",
    "    human_instruction = template + text_graph + df_text['Instruction'][i]\n",
    "    human_instruction = {\"from\": \"human\", \"value\": human_instruction}\n",
    "    gpt_response = df_text['Response'][i]\n",
    "    gpt_response = {\"from\": \"gpt\", \"value\": gpt_response}\n",
    "    new_line.append(human_instruction)\n",
    "    new_line.append(gpt_response)\n",
    "    new_line = {\"conversations\": new_line}\n",
    "    new_text.append(new_line)\n",
    "    # print(json.dumps(new_line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/train_with_eval_dataset/with_module_head/graph_as_prefix/availiable_for_graphcoder/conversations.json', 'w') as f:\n",
    "    # for line in new_text:\n",
    "    #     f.write(json.dumps(line) + '\\n')\n",
    "    json.dump(new_text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_graph_df = df_mm[['nodes', 'edge_attrs', 'connectivity']]\n",
    "# new_graph_df\n",
    "# new_graph_df.to_json('/data/LPJ/ICML25/graphgpt_dataset/gpt_dataset_construction/rtlcoder_gpt4_v1/import_for_graphgpt/graph.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('/data/LPJ/ICML25/GraphCoder/graphgpt_dataset/train_with_eval_dataset/with_module_head/graph_as_prefix/availiable_for_graphcoder/conversations.json') as f:\n",
    "    data = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Given a submodules interconnection graph: \\n<graph>\\n, \\nnodes: [{'id': 0, 'content': 'clk', 'type': 'input port'}, {'id': 1, 'content': 'rst', 'type': 'input port'}, {'id': 2, 'content': 'instr_mem', 'type': 'input port'}, {'id': 3, 'content': 'reg_file', 'type': 'input port'}, {'id': 4, 'content': 'res_reg_file', 'type': 'output port'}, {'id': 5, 'content': 'fetch', 'type': 'submodule'}, {'id': 6, 'content': 'decode', 'type': 'submodule'}, {'id': 7, 'content': 'execute', 'type': 'submodule'}, {'id': 8, 'content': 'memory', 'type': 'submodule'}, {'id': 9, 'content': 'writeback', 'type': 'submodule'}], \\nedge_attrs: [], \\nconnectivity: [[0, 2, 1, 5, 0, 0, 6, 3, 0, 7, 0, 8, 9], [5, 5, 5, 6, 6, 7, 7, 7, 8, 8, 9, 9, 4]]\\n, Implement a pipeline processor with 5 stages: Fetch, Decode, Execute, Memory, and Writeback.\\n\\nModule name:\\n    stagepipe5\\nInput ports:\\n    clk: Clock signal.\\n    rst: Reset signal, active high.\\n    instr_mem[31:0][0:31]: 32-element instruction memory with 32-bit instructions.\\n    reg_file[31:0][0:31]: 32-element register file with 32-bit registers.\\nOutput ports:\\n    res_reg_file[31:0][0:31]: 32-element result register file with 32-bit registers.\\n\\nImplementation:\\nIn the stagepipe5 module, five pipeline stages are instantiated: fetch_stage, decode_stage, execute_stage, memory_stage, and writeback_stage. The fetch_stage module fetches the next instruction from the instruction memory based on the program counter (pc). The decode_stage module decodes the instruction to identify the source registers (rs1, rs2), destination register (rd), and the operation (op). The execute_stage module performs the operation (addition or subtraction) on the values read from the register file and produces the result. The memory_stage module passes the ALU result to the next stage. Finally, the writeback_stage module writes the result back to the register file. The pc is updated in the fetch_stage to fetch the next instruction in the following cycle. The pipeline ensures continuous instruction processing by passing intermediate data between stages through pipeline registers.\\n\\nGive me the complete code.\\nmodule stagepipe5(\\n  input clk,\\n  input rst,\\n  input [31:0] instr_mem [0:31],\\n  input [31:0] reg_file [0:31],\\n  output [31:0] res_reg_file [0:31]\\n);\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[17]['conversations'][0]['value']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
