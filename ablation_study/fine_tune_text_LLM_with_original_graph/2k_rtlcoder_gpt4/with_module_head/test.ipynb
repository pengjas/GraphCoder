{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_conv_path = '/data/LPJ/ICML25/GraphCoder/ablation_study/fine_tune_text_LLM_with_original_graph/2k_rtlcoder_gpt4/without_module_head/graph_as_prefix/conversations.jsonl'\n",
    "suffix_conv_path = '/data/LPJ/ICML25/GraphCoder/ablation_study/fine_tune_text_LLM_with_original_graph/2k_rtlcoder_gpt4/without_module_head/graph_as_suffix/conversations.jsonl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_module_string(text):\n",
    "    # Regex pattern to find the string starting with \"module\" and ending with \";\"\n",
    "    # It uses non-greedy matching to find the shortest match\n",
    "    pattern = r\"module.*?;\"\n",
    "    \n",
    "    # Using re.DOTALL to make the dot match all characters including newline\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        return match.group()  # Returns the matched string\n",
    "    else:\n",
    "        return None  # No match found\n",
    "\n",
    "# # Example usage\n",
    "# input_text = \"\"\"\n",
    "# some initial text\n",
    "# module name=\"example1\" \\n   attribu\\nte=\"   value\";\n",
    "# some other text\n",
    "# module name=\"example2\" attribute=\"another value\";\n",
    "# \"\"\"\n",
    "\n",
    "# # Find the first occurrence\n",
    "# result = find_module_string(input_text)\n",
    "# print(\"Found substring:\", result)\n",
    "\n",
    "# # If you need to find all occurrences instead of just the first one, you can use re.findall\n",
    "# all_matches = re.findall(r\"module.*?;\", input_text, re.DOTALL)\n",
    "# print(\"All found substrings:\", all_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_conv = pd.read_json(suffix_conv_path, lines=True)\n",
    "prefix_conv = pd.read_json(prefix_conv_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2149, 2149)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(suffix_conv), len(prefix_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instruction    Please act as a professional Verilog designer....\n",
       "Response       module buffer (input in, output out);\\n  assig...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix_conv.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(suffix_conv)):\n",
    "    suffix_conv.iloc[i]['Instruction'] = suffix_conv.iloc[i]['Instruction'] + '\\n' + find_module_string(suffix_conv.iloc[i]['Response'])\n",
    "    prefix_conv.iloc[i]['Instruction'] = prefix_conv.iloc[i]['Instruction'] + '\\n' + find_module_string(prefix_conv.iloc[i]['Response'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Please act as a professional Verilog designer. \\n\\nYou are tasked with designing a Verilog module that takes in six inputs and produces three outputs. The inputs are `i_0r0`, `i_0r1`, `i_0a`, `i_1r`, `i_1a`, and `reset`. The outputs are `o_0r0`, `o_0r1`, and `i_1a`. The module should be named `tkj1m1_0`.\\n\\nThe module should have the following behavior:\\n- When `reset` is high, all outputs should be set to 0.\\n- `o_0r0` should be the output of a buffer that takes in `i_0r0`.\\n- `o_0r1` should be the output of a buffer that takes in `i_0r1`.\\n- `i_0a` should be the output of a buffer that takes in `o_0a`.\\n- `i_1a` should be the output of a buffer that takes in `o_0a`.\\n- `i_1r` should be the input of a buffer that takes in `i_1r`.\\n- `o_0r0` should also be the output of an AO222EHD gate that takes in `joinf_0`, `icomplete_0`, and `o_0r0`.\\n- `o_0r1` should also be the output of an AO222EHD gate that takes in `joint_0`, `icomplete_0`, and `o_0r1`.\\n- `joinf_0` should be the output of a buffer that takes in `i_0r0`.\\n- `joint_0` should be the output of a buffer that takes in `i_0r1`.\\n- `icomplete_0` should be the output of a buffer that takes in `i_1r`.\\n\\nYour module should be designed to be as efficient as possible, using the fewest number of gates and buffers while still satisfying the above requirements. Your module should also be designed to be as modular as possible, with each functional block (buffer, AO222EHD gate, etc.) being a separate module.\\n\\nGiven a submodules interconnection graph: \\nnodes: [{'id': 0, 'content': 'a', 'type': 'input port'}, {'id': 1, 'content': 'b', 'type': 'input port'}, {'id': 2, 'content': 'c', 'type': 'input port'}, {'id': 3, 'content': 'd', 'type': 'input port'}, {'id': 4, 'content': 'e', 'type': 'input port'}, {'id': 5, 'content': 'f', 'type': 'input port'}, {'id': 6, 'content': 'out', 'type': 'output port'}], \\nedge_attrs: [], \\nconnectivity: [[5, 0, 4, 1, 3, 2], [6, 6, 6, 6, 6, 6]]\\nmodule buffer (input in, output out);\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix_conv.to_json('/data/LPJ/ICML25/GraphCoder/ablation_study/fine_tune_text_LLM_with_original_graph/2k_rtlcoder_gpt4/with_module_head/graph_as_suffix/conversations.jsonl', orient='records', lines=True)\n",
    "prefix_conv.to_json('/data/LPJ/ICML25/GraphCoder/ablation_study/fine_tune_text_LLM_with_original_graph/2k_rtlcoder_gpt4/with_module_head/graph_as_prefix/conversations.jsonl', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
